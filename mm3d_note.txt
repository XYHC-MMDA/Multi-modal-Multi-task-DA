#### TODO ####
 - anchor_generator, core/evaluation/kitti_eval
 - evaluate
 - dataloader, multi gpu, MMDataParallel
 - loss, log, mmcv.Config
 - joint training, shared optimizer
 - img_indices, sel_label collate

 - loading.multisweeps
 - share .pkl
 - prepare dataset split: usa-singapore, day-night(trained with train_usa & train_singapore, test on test_singapore with highest acc ckpt on val_singapore)
   train_sg: 9665  val_sg: 2770  test_sg:2929
 - pts_bbox_head:loss; mmcv:call_hook('after_train_iter'), backward
 - FPN
 - how register/decorator works? when decorators are called?


### modify ####
mmdet3d/ops/norm.py  # SyncBN

# create data
tools/create_data.py ==> nusc_multi_modal_converter.py

configs:
    _base_:
        datasets: nus-segdet.py  # note: modify data_root
        models: mmda.py

mmdet3d:
    models:
        backbones: resnet34_unet.py
        detectors: mmda.py
datasets:
    pipelines:
        loading.py: LoadSegDetPointsFromFile, LoadFrontImage
        transforms_3d.py: SegDetPointsRangeFilter
    nusc_multi_modal_dataset.py
    gt_bboxes_3d: <class 'mmdet3d.core.bbox.structures.lidar_box3d.LiDARInstance3DBoxes'>


#### cmds ####
CUDA_VISIBLE_DEVICES=5 python tools/train.py ./configs/pointpillars/nus_mmda.py --work-dir ./checkpoints/v0

CUDA_VISIBLE_DEVICES=5 python tools/mini_train.py ./configs/pointpillars/nus_mmda.py --work-dir ./checkpoints/debug

CUDA_VISIBLE_DEVICES=5 python tools/train.py ./configs/pointpillars/hv_pointpillars_fpn_sbn-all_4x8_2x_nus-3d.py --work-dir ./results/debug

CUDA_VISIBLE_DEVICES=8 python tools/a_test.py configs/pointpillars/nus_mmda.py checkpoints/v0/epoch_24.pth --out checkpoints/v0/epoch_24.pkl --eval mAP

CUDA_VISIBLE_DEVICES=6 python tools/test.py configs/pointpillars/hv_pointpillars_fpn_sbn-all_4x8_2x_nus-3d.py checkpoints/reproduce/epoch_24.pth --out checkpoints/reproduce/epoch_24.pkl --eval mAP --json checkpoints/reproduce

CUDA_VISIBLE_DEVICES=1 python tools/test.py configs/pointpillars/hv_pointpillars_fpn_sbn-all_4x8_2x_nus-3d.py pretrained/hv_pointpillars_fpn_sbn-all_4x8_2x_nus-3d_20200620_230405-2fa62f3d.pth --out pretrained/hv_pointpillars_fpn_sbn-all_4x8_2x_nus-3d_20200620_230405-2fa62f3d.pkl --eval mAP


python tools/create_data.py nuscenes --root-path ../nuscenes_unzip --out-dir ../nuscenes_unzip --extra-tag nuscenes


#### model dict ####
 - type: 'MVXFasterRCNN':
   mmdet3d/models/detectors/mvx_faster_rcnn.py  inherit  mvx_two_stage.py(same folder)

 - self.pts_voxel_layer; model.pts_voxel_layer
   mmdet3d/ops/voxel/voxelize: 
      Voxelization(nn.Module); 
      return voxels_out, coors_out, num_points_per_voxel_out
   hard_voxelize: src/voxelization_cpu.cpp, src/voxelization_cuda.cu,

 - self.pts_voxel_encoder; model.pts_voxel_encoder: HardVFE
   mmdet3d/models/voxel_encoders/voxel_encoder.py
   VFELayer: ./utils.py

 - self.pts_middle_encoder: model.pts_middle_encoder: PointPillarsScatter
   mmdet3d/models/middle_encoders/pillar_scatter.py
   
 - self.pts_backbone: model.pts_backbone: SECOND
   mmdet3d/models/backbones/second.py

 - self.pts_neck: model.pts_neck: FPN
   mmdet/models/necks/fpn.py

 - self.pts_bbox_head: model.pts_bbox_head: Anchor3DHead
   mmdet3d/models/dense_heads/anchor3d_head.py



### forward train ###
tools/train.py:
    train_detector()
mmdet.apis.train.py:
    train_detector() ==> runner.run(data_loaders)

mmcv/runner/base_runner.py: EpochBasedRunner: 
	run(data_loaders) ==> train(data_loader) ==> run_iter(data_batch) ==> self.model.train_step(data_batch, optimizer, **kwargs(None))

mmcv/parallel/data_parallel.py: MMDataParallel
    train_step(*inputs, **kwargs):
        inputs, kwargs = self.scatter(inputs, kwargs, self.device_ids)
        return self.module.train_step(*inputs[0], **kwargs[0])

mmdet/models/detectors/base.py: BaseDetector:
    train_step(data_batch, optimizer) ==> forward(**data_batch)

mmdet3d/models/detectors/base.py: Base3DDetector:
	forward(**data_batch) ==> forward_train(**data_batch)

mmdet3d/models/detectors/mvx_two_stage.py: MVXTwoStageDetector: 
	forward_train(**data_batch)  # return losses(dict)


### forward test ###
tools/mmda_test.py:
    model = MMDataParallel(model, device_ids=[0])
    outputs = mmda_single_gpu_test(model, data_loader, args.show, args.show_dir)

mmdet3d/apis/test.py: mmda_single_gpu_test
    seg_res, box_res = model(return_loss=False, rescale=True, **data)

mmcv/parallel/data_parallel.py: MMDataParallel
    forward():
        return super().forward(*inputs, **kwargs)  # TODO: where is scatter???



#### dataset ####
mmdet3d/datasets/custom_3d.py, nuscenes_dataset.py: Custom3DDataset, NuScenesDataset
	self.data_infos=NuScenesDataset.load_annotations() ==> Custom3DDataset.__getitem__() ==> Custom3DDataset.prepare_train_data() ==> NuScenesDataset.get_data_info(), self.pipeline() ==> mmdet3d/datasets/pipelines/loading.py



